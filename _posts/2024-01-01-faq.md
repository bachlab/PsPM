---
layout: post
title: FAQ
permalink: /faq/
---


## Why should I use PsPM?
There are two alternatives to PsPM
for SCR analysis: standard peak scoring, and Ledalab. All these three
approaches aim at making a statement about an unobservable psychological
process (sympathetic arousal), given skin conductance data. We prefer
to use any method that has the highest chance of recovering this
unobservable process. But how can we know how well a method recovers a
hidden process? One possibility is to induce known psychological states,
for example showing aversive and neutral images which we know induce
strong and weak sympathetic arousal. Ideally, these two conditions
should be separable by any analysis method. PsPM separates such two
known conditions much better (significantly better) than the other two
approaches (Bach DR, 2014, Biological Psychology 103:63-68: A head-to-head
comparison of SCRalyze and Ledalab, two model-based methods for skin
conductance analysis).

## I have previously used SCRalyze. What's the difference to PsPM?
PsPM incorporates the previous software package
SCRalyze and offers all features of SCRalyze plus many more. If
you started working on a project with SCRalyze and want to
continue, you can still find previous software versions, help,
and recources on <a title="http://scralyze.sourceforge.net"
href="http://scralyze.sourceforge.net">http://scralyze.sourceforge.net</a>.

## What's the best way of recording SCR?
It's extremely simple - there
is no mystery to it. Only a few dos and don'ts: Do use cup electrodes,
don't use dry plate electrodes (to minimise artefacts). Do use 0.5%
NaCl gel, don't use EEG or ECG gel (to avoid distorting responses). Do
record on palm (e.g., thenar/hypothenar, or two fingers) or plant (inner
arch). We have shown that it does not really matter where precisely you
record (see Bach et al., 2010, "Modelling event-related skin conductance
responses"). Make sure the subject does not move the limb you're recording
from. Do make sure there is no electromagnetic noise. Do use any kind
of voltage coupler (e.g. based on a Wheatstone bridge, or differential
amplifier). If you are using non-standard equipment and are unsure
whether your responses conform to the canonical response function:
use 10-20 simple stimuli (e.g. white noise bursts), separated by 30-40
seconds of rest, average responses, and check out how they look.

## Can I import text data?
Yes you can. Text files must contain one data channel per column and
no headers or annotations. Note that text import can be inconvenient
because it involves very large files and might push matlab to its memory
limits. We have been able in the past to provide import interfaces for
different proprietary data formats, and if you give us details of your
format, we might be able to help you import your data in a quicker and
more comfortable way.

## How can I import a matlab variable into PsPM?
You cannot import variables from the matlab workspace; you need to save
them to a .mat file - one file per data set (e. g. per subject). This .mat
file will have to contain one variable called "data". This will be either
a data points x columns matrix, or a cell array where each cell in the
array is a one-column vector pertaining to one data channel. SCRalyze
will not recognize time stamps as such. Rather, it will ask you for a
sample rate. If the samples are not spaced evenly, let me know; we could
then think of how to import the data otherwise.

## How do I construct a regressor file for GLM?
Regressor files for GLM are similar to the ones used in SPM. Imagine
a simple 2 x 2 factorial design. Each of the four cells needs to be
specified separately. A regressor file might be created like this:
```MATLAB
names = {'Condition A', 'Condition B', 'Condition C', 'Condition D'};
onsets = {[5 34 55], [9 42 48], [18 30 38], [14 23 27]};
save('Regressors.mat', 'names', 'onsets');
```
where e.g. there
are three trials for each cell of the design, specified in seconds from
file start. After estimating the GLM parameters, you have one summary
statistic per cell of the design, which you can use to test your main
effects and interaction on the second level (i.e. across the group).
Don't forget to save your file with e.g. the last line above.

## How do I specify my regressors?
*In my experiment, there are choices (positive and negative)
with different payout levels and type etc., which will comprise
60 conditions. Does each type of choice have to be in a separate
column? Should each column correspond to a condition (60 columns)?*
Typically, psychological experiments use factorial designs (i. e. designs
in which each condition corresponds to a combination of factor levels,
and all factors are fully crossed). In this case, each regressor
should correspond to a cell (that is, a condition, i. e. a particular
combination of factor levels) of your design. You can then specify
all sorts of contrasts (i. e. main effects, interactions, polynomial
contrasts etc.) using the contrast feature, and test them on the
second level, across the group.  In this case, however, there are 60
conditions. Therefore, it is worth thinking about an alternative. In
fact, typical factorial designs make no assumption about any ordering
of the factor levels. The levels of the independent variable are treated
as categorical. In the present case, some factors - for example, payoff
value - are clearly numerical. Here, one can greatly simplify the number
of regressors. Take the payoff value. A main effect of payoff value in
a full factorial design tests the omnibus H1: "There is some effect
whatsoever of payoff level". This includes effects such as "The 23rd
payoff level produces greater SCR than the 2nd level, in the absence of
any other differences between payoff level." This might be completely
uninteresting in the case of a quasi-continuous, numerical factor. You
might be more interested in hypotheses of the kind: "There is a linear
effect of payoff level on SCR", "There is an inverted U-relation of
payoff level and SCR" etc. These are polynomial contrasts of lower order.
You could surely use 60 regressors and define such polynomial contrasts
later. But you can also use them in your design matrix: for example,
specify ALL events in one regressor. Then, use "parametric modulators"
to encode your conditions. A categorical condition (for example, positive
vs. negative) will just consist of -1 and 1, and for a numerical factor,
you could specify for example, linear and quadratic effects.  Note that
if your design is not fully crossed, then the parametric modulators will
be correlated. They get decorrelated during processing, and this means
that the ordering of pmods might have an influence on your results.

## When I trim my EDA data for GLM analyses, can I still use onset files where the onsets are relative to the beginning of the measurement, or do I have to trim the onsets as well?
The onset file must be relative to the data file you feed into
analysis. This means, you need to trim the onset file as well. Actually,
there are two ideas behind trimming. One is to get rid of artefacts and
long stretches of data before and after the experiment. The other idea
is that if you record GSR inside the scanner, you can trim the SCRalyze
data files in the same way that you trim your fMRI data. Then you can
use the same onset files for SPM and SCRalyze.

## How do I specify episodes for SF?
There are several ways of specifying episodes for SF. The simplest is
if each data file contains exactly one episode. Simply specify "whole"
in the time unit menu.  If the data files contain more than just one
episode, you can specify episodes manually, or, more conveniently, use
episode files. A simple file might look like this:
```MATLAB
names = {'onsets', 'offsets'};
onsets = {[10 50 100], [40 80 160]};
save('Regressors.mat', 'names', 'onsets');
```
 This file contains
three episodes, one from 10-40 seconds, another from 50-80 seconds,
and a third one from 100-160 seconds.  Don't forget to save your file
with e.g.  the last line above. The same episodes
can be specified with
```MATLAB
epochs = [10 40; 50 80; 100 160];
```
Again, don't forget to save.

## I have calculated contrasts. What do the numbers mean?
The meaning of contrast estimates depends on the basis function you
use. For the canonical SCRF provided in the software, contrast estimates
correspond to the peak amplitude of an ideal SCR. For example, if you
compare two conditions, and the contrast estimate is 1, then this means
that the average difference between the SCR peak amplitudes in the two
conditions is 1 unit. If you converted your data into µS during import
(which we always recommend), then a contrast estimate of 1 corresponds
to a peak amplitude difference of 1 µS.

## In what cases should I use a DCM, and when should I not?
Dynamic causal modelling for SCR was developed to analyse experiments
where the timepoint and duration of a response are unknown and have to
be estimated. This is a pretty general description, and there are many
cases where either DCM or GLM can be used. However, if you only analyse
SCR evoked by short stimulus - don't use DCM. In this case, a GLM is
sufficient and will be much more robust.

## How can I deconvolve spontaneous fluctuation of skin conductance (after filtered SCL) in order to get the onsets and durations so that I can use them in SPM for modeling?
In principle, this is simple enough you just need to do DCM for SF
and manually extract the onsets and amplitudes of the spontaneous
fluctuations - durations are assumed to be fixed. There are a few
technical issues to be considered: (1) all DCMs for SCR are susceptible
to artefacts, in particular spikes with downward deflection which
change the apparent signal baseline. The most difficult artefacts I
have seen so far were induced by small subject movements in the static
field. (2) DCM inversion might take a while if your scanner runs are
long - several hours per inversion is not unusual, but this of course
depends on your computation power. (3) If you model the extracted onsets
as stick functions, modulate these by amplitude of SF, and convolve with
an HRF, the result will look pretty similar to the original (filtered)
SCR data. This is because HRF and SCRF are somewhat similar. Of course,
there all all sorts of other things one might do: for example, ignore
SF amplitude (because SF amplitude does not depend on tonic arousal
e. g. during public speaking anticipation, while the number of SF does),
or only analyse SF in certain time windows, etc.  This is how you do it:
define episodes (e. g. scanner runs), and run DCM for SF (see SCRalyze
manual). Load the resulting SF file and extract [sf.dcm.stat.t] (onset
time from episode start in seconds) and [sf.dcm.stat.a] (amplitude in
your units). Note that this type of DCM does not estimate the number of
responses - it assumes a fixed number and estimates their amplitude. The
amplitude of "unnecessary" SFs will be estimated close to zero. Therefore
it is a good idea to exclude SF below a certain amplitude. A sensible
treshold is 0.1 mcS (see Bach, Daunizeau et al., Psychophysiology 2011
for details).
